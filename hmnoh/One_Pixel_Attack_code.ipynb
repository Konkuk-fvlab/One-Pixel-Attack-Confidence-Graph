{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tXMlBYFwL6JX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4caaacef-1898-4113-e6bb-c1c6d5502e00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'one-pixel-attack-keras'...\n",
            "remote: Enumerating objects: 385, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 385 (delta 22), reused 35 (delta 17), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (385/385), 45.38 MiB | 29.43 MiB/s, done.\n",
            "Resolving deltas: 100% (220/220), done.\n",
            "renamed 'one-pixel-attack-keras/1_one_pixel_attack_cifar10.ipynb' -> './1_one_pixel_attack_cifar10.ipynb'\n",
            "renamed 'one-pixel-attack-keras/2_one-pixel-attack-imagenet.ipynb' -> './2_one-pixel-attack-imagenet.ipynb'\n",
            "renamed 'one-pixel-attack-keras/attack.py' -> './attack.py'\n",
            "renamed 'one-pixel-attack-keras/CONTRIBUTING.md' -> './CONTRIBUTING.md'\n",
            "renamed 'one-pixel-attack-keras/data' -> './data'\n",
            "renamed 'one-pixel-attack-keras/differential_evolution.py' -> './differential_evolution.py'\n",
            "renamed 'one-pixel-attack-keras/helper.py' -> './helper.py'\n",
            "renamed 'one-pixel-attack-keras/images' -> './images'\n",
            "renamed 'one-pixel-attack-keras/LICENSE' -> './LICENSE'\n",
            "renamed 'one-pixel-attack-keras/networks' -> './networks'\n",
            "renamed 'one-pixel-attack-keras/README.md' -> './README.md'\n",
            "renamed 'one-pixel-attack-keras/requirements.txt' -> './requirements.txt'\n",
            "renamed 'one-pixel-attack-keras/train.py' -> './train.py'\n"
          ]
        }
      ],
      "source": [
        "# If running in Google Colab, import files\n",
        "try:\n",
        "    import google.colab\n",
        "    in_colab = True\n",
        "except:\n",
        "    in_colab = False\n",
        "\n",
        "if in_colab:\n",
        "    !git clone https://github.com/aiken516/one-pixel-attack-keras.git\n",
        "    !mv -v one-pixel-attack-keras/* .\n",
        "    !rm -rf one-pixel-attack-keras\n",
        "\n",
        "# Python Libraries\n",
        "%matplotlib inline\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "from keras.datasets import cifar10\n",
        "from keras import backend as K\n",
        "\n",
        "# Custom Networks\n",
        "from networks.lenet import LeNet\n",
        "#from networks.pure_cnn import PureCnn\n",
        "from networks.network_in_network import NetworkInNetwork\n",
        "from networks.resnet import ResNet\n",
        "from networks.densenet import DenseNet\n",
        "from networks.wide_resnet import WideResNet\n",
        "from networks.capsnet import CapsNet\n",
        "\n",
        "# Helper functions\n",
        "from differential_evolution import differential_evolution\n",
        "import helper\n",
        "\n",
        "import time\n",
        "\n",
        "matplotlib.style.use('ggplot')\n",
        "np.random.seed(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLpB45gxL6JY"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4VxN7lYL6JY"
      },
      "source": [
        "For this attack, we will use the [Cifar10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) packaged by Keras. The task of the dataset is to correctly classify a 32x32 pixel image in 1 of 10 categories (e.g., bird, deer, truck).\n",
        "\n",
        "The code below will load the Cifar10 dataset. Keras will need to download the dataset if it is not cached locally already."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p2W475HxL6JZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3635301-f096-40ca-c086-92d10f9ccce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FO9iBXBcL6JZ"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JP-_mWqfL6Ja"
      },
      "outputs": [],
      "source": [
        "def perturb_image(xs, img):\n",
        "    # If this function is passed just one perturbation vector,\n",
        "    # pack it in a list to keep the computation the same\n",
        "    if xs.ndim < 2:\n",
        "        xs = np.array([xs])\n",
        "\n",
        "    # Copy the image n == len(xs) times so that we can\n",
        "    # create n new perturbed images\n",
        "    tile = [len(xs)] + [1]*(xs.ndim+1)\n",
        "    imgs = np.tile(img, tile)\n",
        "\n",
        "    # Make sure to floor the members of xs as int types\n",
        "    xs = xs.astype(int)\n",
        "\n",
        "    for x,img in zip(xs, imgs):\n",
        "        # Split x into an array of 5-tuples (perturbation pixels)\n",
        "        # i.e., [[x,y,r,g,b], ...]\n",
        "        pixels = np.split(x, len(x) // 5)\n",
        "        for pixel in pixels:\n",
        "            # At each pixel's x,y position, assign its rgb value\n",
        "            x_pos, y_pos, *rgb = pixel\n",
        "            img[x_pos, y_pos] = rgb\n",
        "\n",
        "    return imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FFmZle1xL6Jb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425dbab1-0dfb-4415-89b4-33b602dfb0b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded lenet\n",
            "Successfully loaded resnet\n"
          ]
        }
      ],
      "source": [
        "lenet = LeNet()\n",
        "resnet = ResNet()\n",
        "\n",
        "models = [lenet, resnet] #, resnet]\n",
        "\n",
        "## Uncomment below to load more models to play with. Make sure the model files exist by training or downloading them.\n",
        "\n",
        "# lenet = LeNet()\n",
        "# pure_cnn = PureCnn()\n",
        "# net_in_net = NetworkInNetwork()\n",
        "# resnet = ResNet()\n",
        "# densenet = DenseNet()\n",
        "# wide_resnet = WideResNet()\n",
        "# capsnet = CapsNet()\n",
        "\n",
        "# models = [lenet, pure_cnn, net_in_net, resnet, densenet, wide_resnet, capsnet]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_confidence(image_id):\n",
        "    img_original = x_test[image_id].copy()\n",
        "    true_class = y_test[image_id, 0]\n",
        "\n",
        "    target_count = np.zeros(10, dtype=int)\n",
        "\n",
        "    helper.plot_image(img_original)\n",
        "\n",
        "    prior_confidence =  model.predict_one(img_original)\n",
        "    print(\"prior_confidence: {0}\".format(prior_confidence[true_class]))\n",
        "\n",
        "    diff_list = [[0,0,0]]\n",
        "    rgb = [0, 0, 0]\n",
        "\n",
        "    array = np.empty((0, 32, 32, 3))\n",
        "\n",
        "    for x in range(32):\n",
        "        for y in range(32):\n",
        "          for i in range(3):\n",
        "              if img_original[x][y][i] >= 128:\n",
        "                rgb[i] = 0\n",
        "              else:\n",
        "                rgb[i] = 255\n",
        "\n",
        "          pixel = np.array([x, y,  rgb[0], rgb[1], rgb[2]])\n",
        "          perturbed_image = perturb_image(pixel, img_original)\n",
        "\n",
        "          array = np.append(array, np.array((perturbed_image)), axis=0)\n",
        "\n",
        "    processed = model.color_process(array)\n",
        "    result = model._model.predict(processed, batch_size=1024,verbose=0)\n",
        "\n",
        "    for i in range(1024):\n",
        "        target_count[np.argmax(result[i] - prior_confidence)] += 1\n",
        "\n",
        "    target_class = np.argmax(target_count)\n",
        "    print(\"target_class: {0}\".format(class_names[target_class]))\n",
        "\n",
        "    for i in range(1024):\n",
        "        after_confidence =  result[i][target_class]\n",
        "        #print(\"after_confidence: {0}\".format(after_confidence))\n",
        "\n",
        "        diff_confidence = abs(after_confidence - prior_confidence[target_class])\n",
        "        #print(\"diff_confidence: {0}\".format(diff_confidence))\n",
        "\n",
        "        if diff_confidence > 0:\n",
        "            for diff_index in range(len(diff_list)):\n",
        "                if diff_confidence >= diff_list[diff_index][1]:\n",
        "                    diff_list.insert(diff_index, [i, diff_confidence])\n",
        "                    if (len(diff_list) > 30):\n",
        "                        diff_list.pop()\n",
        "                    break\n",
        "\n",
        "    return diff_list[0][0]"
      ],
      "metadata": {
        "id": "YxvtcocmIkmJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_confidence(image_id):\n",
        "    img_original = x_test[image_id].copy()\n",
        "    true_class = y_test[image_id, 0]\n",
        "\n",
        "    target_count = np.zeros(10, dtype=int)\n",
        "\n",
        "    helper.plot_image(img_original)\n",
        "\n",
        "    prior_confidence =  model.predict_one(img_original)\n",
        "    print(\"prior_confidence: {0}\".format(prior_confidence[true_class]))\n",
        "\n",
        "    diff_list = [[0,0,0]]\n",
        "    rgb = [0, 0, 0]\n",
        "\n",
        "    array = np.empty((0, 32, 32, 3))\n",
        "\n",
        "    for x in range(32):\n",
        "        for y in range(32):\n",
        "          for i in range(3):\n",
        "              if img_original[x][y][i] >= 128:\n",
        "                rgb[i] = 0\n",
        "              else:\n",
        "                rgb[i] = 255\n",
        "\n",
        "          pixel = np.array([x, y,  rgb[0], rgb[1], rgb[2]])\n",
        "          perturbed_image = perturb_image(pixel, img_original)\n",
        "\n",
        "          array = np.append(array, np.array((perturbed_image)), axis=0)\n",
        "\n",
        "    processed = model.color_process(array)\n",
        "    result = model._model.predict(processed, batch_size=1024,verbose=0) - prior_confidence\n",
        "\n",
        "    for i in range(1024):\n",
        "        target_count[np.argmax(result[i])] += 1\n",
        "\n",
        "    target_class = np.argmax(target_count)\n",
        "    print(\"target_class: {0}\".format(class_names[target_class]))\n",
        "\n",
        "    for i in range(1024):\n",
        "        diff_confidence =  result[i][target_class]\n",
        "\n",
        "        if diff_confidence > 0:\n",
        "            for diff_index in range(len(diff_list)):\n",
        "                if diff_confidence >= diff_list[diff_index][1]:\n",
        "                    diff_list.insert(diff_index, [i, diff_confidence])\n",
        "                    if (len(diff_list) > 30):\n",
        "                        diff_list.pop()\n",
        "                    break\n",
        "\n",
        "    return diff_list[0][0], target_count"
      ],
      "metadata": {
        "id": "HXw9hA8CIpN3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_momentum(image_id, pixel):\n",
        "    img = x_test[image_id].copy()\n",
        "    true_class = y_test[image_id, 0]\n",
        "\n",
        "    x = pixel[0]\n",
        "    y = pixel[1]\n",
        "    r = pixel[2]\n",
        "    g = pixel[3]\n",
        "    b = pixel[4]\n",
        "\n",
        "    rate = 5000\n",
        "    momentum_rate = 0.99\n",
        "\n",
        "    v_r = 0 #속도\n",
        "    v_g = 0\n",
        "    v_b = 0\n",
        "\n",
        "    for i in range(100):\n",
        "        node = np.array([x, y, r, g, b])\n",
        "        ori_con = model.predict_one(perturb_image(node, img))[true_class]\n",
        "\n",
        "        #if (ori_con < 0.5):\n",
        "        #    return True\n",
        "\n",
        "        print(\"x:{0}, y:{1}, rgb:({2}, {3}, {4}), confidence: {5})\".format(x, y, r, g, b, ori_con))\n",
        "        array = np.empty((0, 32, 32, 3))\n",
        "\n",
        "        array = np.append(array, np.array((perturb_image(np.array([x, y, bound(r + 1), g, b]), img))), axis=0)\n",
        "        array = np.append(array, np.array((perturb_image(np.array([x, y, bound(r - 1), g, b]), img))), axis=0)\n",
        "        array = np.append(array, np.array((perturb_image(np.array([x, y, r, bound(g + 1), b]), img))), axis=0)\n",
        "        array = np.append(array, np.array((perturb_image(np.array([x, y, r, bound(g - 1), b]), img))), axis=0)\n",
        "        array = np.append(array, np.array((perturb_image(np.array([x, y, r, g, bound(b + 1)]), img))), axis=0)\n",
        "        array = np.append(array, np.array((perturb_image(np.array([x, y, r, g, bound(b - 1)]), img))), axis=0)\n",
        "\n",
        "        processed = model.color_process(array)\n",
        "        result = model._model.predict(processed, batch_size=6, verbose=0)\n",
        "\n",
        "        diff_r = result[0][true_class] - result[1][true_class]\n",
        "        print(\"diff_r: {0}\".format(diff_r))\n",
        "\n",
        "        diff_g = result[2][true_class] - result[3][true_class]\n",
        "        print(\"diff_g: {0}\".format(diff_g))\n",
        "\n",
        "        diff_b = result[4][true_class] - result[5][true_class]\n",
        "        print(\"diff_b: {0}\".format(diff_b))\n",
        "\n",
        "        v_r = momentum_rate * v_r - diff_r * rate\n",
        "        v_g = momentum_rate * v_g - diff_g * rate\n",
        "        v_b = momentum_rate * v_b - diff_b * rate\n",
        "\n",
        "        if (abs(diff_r) + abs(diff_g) + abs(diff_b) < 0.0001):\n",
        "            break\n",
        "\n",
        "        new_r = bound(r + v_r)\n",
        "        new_g = bound(g + v_g)\n",
        "        new_b = bound(b + v_b)\n",
        "\n",
        "        #if (new_r == r and new_g == g and new_b == b):\n",
        "        #    break\n",
        "\n",
        "        r = new_r\n",
        "        g = new_g\n",
        "        b = new_b\n",
        "\n",
        "    helper.plot_image(perturb_image(np.array([x, y, r, g, b]), img))\n",
        "    print(\"Attack Confidence:\" + str(model.predict_one(perturb_image(np.array([x, y, r, g, b]), img))[true_class]))\n",
        "\n",
        "def bound(num):\n",
        "    return int(max(0, min(255,num)))"
      ],
      "metadata": {
        "id": "iAcU1TdVAU-v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet\n",
        "image_id = 384\n",
        "\n",
        "diff_num, target_count = pixel_confidence(image_id)\n",
        "print(diff_num)\n",
        "print(target_count)\n",
        "x = diff_num // 32\n",
        "y = diff_num % 32\n",
        "pixel = np.array([x, y, x_test[image_id][x][y][0], x_test[image_id][x][y][1], x_test[image_id][x][y][2]])\n",
        "\n",
        "#gradient_descent_momentum(image_id, pixel)"
      ],
      "metadata": {
        "id": "lBpsWrfCDFLN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "10883b7d-c1c0-4652-e9c7-c33f99b09fd4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 52ms/step\n",
            "prior_confidence: 0.7066169381141663\n",
            "target_class: dog\n",
            "559\n",
            "[  0   0 365   0   0 658   1   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_ascent_momentum_target(image_id, pixel, target_class):\n",
        "    img = x_test[image_id]\n",
        "\n",
        "    x = pixel[0]\n",
        "    y = pixel[1]\n",
        "    r = pixel[2]\n",
        "    g = pixel[3]\n",
        "    b = pixel[4]\n",
        "\n",
        "    rate = 1000\n",
        "    momentum_rate = 0.99\n",
        "\n",
        "    v_r = 0 #속도\n",
        "    v_g = 0\n",
        "    v_b = 0\n",
        "\n",
        "    for i in range(1000):\n",
        "        node = np.array([x, y, r, g, b])\n",
        "\n",
        "        print(\"x:{0}, y:{1}, rgb:({2}, {3}, {4}), confidence: {5})\".format(x, y, r, g, b, model.predict_one(perturb_image(node, img))[target_class]))\n",
        "\n",
        "        array = np.empty((0, 32, 32, 3))\n",
        "\n",
        "        array = np.append(array, np.array((perturb_image(np.array([x, y, bound(r + 1), g, b]), img))), axis=0)\n",
        "        array = np.append(array, np.array((perturb_image(np.array([x, y, bound(r - 1), g, b]), img))), axis=0)\n",
        "        array = np.append(array, np.array((perturb_image(np.array([x, y, r, bound(g + 1), b]), img))), axis=0)\n",
        "        array = np.append(array, np.array((perturb_image(np.array([x, y, r, bound(g - 1), b]), img))), axis=0)\n",
        "        array = np.append(array, np.array((perturb_image(np.array([x, y, r, g, bound(b + 1)]), img))), axis=0)\n",
        "        array = np.append(array, np.array((perturb_image(np.array([x, y, r, g, bound(b - 1)]), img))), axis=0)\n",
        "\n",
        "        processed = model.color_process(array)\n",
        "        result = model._model.predict(processed, batch_size=6, verbose=0)\n",
        "\n",
        "        diff_r = result[0][target_class] - result[1][target_class]\n",
        "        #print(\"diff_r: {0}\".format(diff_r))\n",
        "\n",
        "        diff_g = result[2][target_class] - result[3][target_class]\n",
        "        #print(\"diff_g: {0}\".format(diff_g))\n",
        "\n",
        "        diff_b = result[4][target_class] - result[5][target_class]\n",
        "        #print(\"diff_b: {0}\".format(diff_b))\n",
        "\n",
        "        v_r = momentum_rate * v_r + diff_r * rate\n",
        "        v_g = momentum_rate * v_g + diff_g * rate\n",
        "        v_b = momentum_rate * v_b + diff_b * rate\n",
        "\n",
        "        new_r = bound(r + v_r)\n",
        "        new_g = bound(g + v_g)\n",
        "        new_b = bound(b + v_b)\n",
        "\n",
        "        if (new_r == r and new_g == g and new_b == b):\n",
        "            break\n",
        "\n",
        "        r = new_r\n",
        "        g = new_g\n",
        "        b = new_b\n",
        "\n",
        "    helper.plot_image(perturb_image(np.array([x, y, r, g, b]), img))\n",
        "    print(\"Attack Confidence:\" + str(model.predict_one(perturb_image(np.array([x, y, r, g, b]), img))[target_class]))\n",
        "\n",
        "def bound(num):\n",
        "    return int(max(0, min(255,num)))"
      ],
      "metadata": {
        "id": "Pl4y1d60s10e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet\n",
        "image_id = 384\n",
        "\n",
        "diff_num = pixel_confidence(image_id)\n",
        "print(diff_num)\n",
        "x = diff_num // 32\n",
        "y = diff_num % 32\n",
        "pixel = np.array([x, y, x_test[image_id][x][y][0], x_test[image_id][x][y][1], x_test[image_id][x][y][2]])\n",
        "\n",
        "for i in range(10):\n",
        "    gradient_ascent_momentum_target(image_id, pixel, i)"
      ],
      "metadata": {
        "id": "vHvU-aSxtQ1T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "184a5d7d-6105-4ec1-f107-0c4b4fd85abb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-46f1f1e6f8dc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m384\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdiff_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff_num\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pixel_confidence' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixing gradient due to the number of calling predict function\n",
        "\n",
        "def score_init(sensitive_x, sensitive_y, r, g, b, img, model, momentum, learning_rate, target_class):\n",
        "\n",
        "    true_class = y_test[image_id, 0]\n",
        "    vr, vg, vb = 0, 0, 0\n",
        "    print(r, g, b)\n",
        "\n",
        "    batch_List = np.empty((0, 32, 32, 3))\n",
        "\n",
        "    decr_red = np.array([sensitive_x, sensitive_y, bound(r-1), g, b])\n",
        "    perturbed_d_Red = perturb_image(decr_red, img)\n",
        "    incr_red = np.array([sensitive_x, sensitive_y, bound(r+1), g, b])\n",
        "    perturbed_i_Red = perturb_image(incr_red, img)\n",
        "\n",
        "    batch_List = np.append(batch_List, np.array(perturbed_d_Red), axis = 0)\n",
        "    batch_List = np.append(batch_List, np.array(perturbed_i_Red), axis = 0)\n",
        "    #decr_red_confidence = model.predict_one(perturb_image(decr_red, img))[target_class]\n",
        "    #incr_red_confidence = model.predict_one(perturb_image(incr_red, img))[target_class]\n",
        "\n",
        "    #diff_r = (incr_red_confidence - decr_red_confidence)\n",
        "    #print(diff_r)\n",
        "\n",
        "    decr_green = np.array([sensitive_x, sensitive_y, r, bound(g-1), b])\n",
        "    perturbed_d_Green = perturb_image(decr_green, img)\n",
        "    incr_green = np.array([sensitive_x, sensitive_y, r, bound(g+1), b])\n",
        "    perturbed_i_Green = perturb_image(incr_green, img)\n",
        "\n",
        "    batch_List = np.append(batch_List, np.array(perturbed_d_Green), axis = 0)\n",
        "    batch_List = np.append(batch_List, np.array(perturbed_i_Green), axis = 0)\n",
        "    #decr_green_confidence = model.predict_one(perturb_image(decr_green, img))[target_class]\n",
        "    #incr_green_confidence = model.predict_one(perturb_image(incr_green, img))[target_class]\n",
        "\n",
        "\n",
        "    #diff_g = (incr_green_confidence - decr_green_confidence)\n",
        "    #print(diff_g)\n",
        "\n",
        "    decr_blue = np.array([sensitive_x, sensitive_y, r, g, bound(b-1)])\n",
        "    perturbed_d_Blue = perturb_image(decr_blue, img)\n",
        "    incr_blue = np.array([sensitive_x, sensitive_y, r, g, bound(b+1)])\n",
        "    perturbed_i_Blue = perturb_image(incr_blue, img)\n",
        "\n",
        "    batch_List = np.append(batch_List, np.array(perturbed_d_Blue), axis = 0)\n",
        "    batch_List = np.append(batch_List, np.array(perturbed_i_Blue), axis = 0)\n",
        "    #decr_blue_confidence = model.predict_one(perturb_image(decr_blue, img))[target_class]\n",
        "    #incr_blue_confidence = model.predict_one(perturb_image(incr_blue, img))[target_class]\n",
        "\n",
        "    processed = model.color_process(batch_List)\n",
        "    ConfidenceList = model._model.predict(processed, batch_size = 6, verbose = 0) # decr_red_confidence = result[0][target_class]\n",
        "\n",
        "\n",
        "    #diff_b = (incr_blue_confidence - decr_blue_confidence)\n",
        "    #print(diff_b)\n",
        "\n",
        "    diff_r = (ConfidenceList[1][target_class] - ConfidenceList[0][target_class])\n",
        "    diff_g = (ConfidenceList[3][target_class] - ConfidenceList[2][target_class])\n",
        "    diff_b = (ConfidenceList[5][target_class] - ConfidenceList[4][target_class])\n",
        "\n",
        "    vr = momentum * vr + learning_rate * diff_r # r axis vector\n",
        "    vg = momentum * vg + learning_rate * diff_g # g axis vector\n",
        "    vb = momentum * vb + learning_rate * diff_b # b axis vector\n",
        "\n",
        "    #print(vr, vg, vb)\n",
        "    new_r = bound(r + vr)\n",
        "    new_g = bound(g + vg)\n",
        "    new_b = bound(b + vb)\n",
        "\n",
        "    xs = np.array([sensitive_x, sensitive_y, new_r, new_g, new_b])\n",
        "    #print(\"new rgb is : \", new_r, new_g, new_b)\n",
        "    predicted_probs = model.predict_one(perturb_image(xs, img))\n",
        "\n",
        "\n",
        "    predicted_class = np.argmax(predicted_probs)\n",
        "    #print(\"init end\\n\")\n",
        "\n",
        "    return new_r, new_g, new_b, predicted_probs, vr, vg, vb"
      ],
      "metadata": {
        "id": "emyudZ4nRwAr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_based_attack(image_id, model, sensitive_x, sensitive_y, target_class):\n",
        "    img = x_test[image_id].copy()\n",
        "    true_class = y_test[image_id, 0]\n",
        "    original_confidence = model.predict_one(img) # will be deleted during experiment\n",
        "    print(\"original confidence is : \", original_confidence[true_class], '\\n')\n",
        "\n",
        "    # Original rgb value, named Prev (original is initial Prev)\n",
        "    prev_r = img[sensitive_x][sensitive_y][0]\n",
        "    prev_g = img[sensitive_x][sensitive_y][1]\n",
        "    prev_b = img[sensitive_x][sensitive_y][2]\n",
        "    print(\"original rgb is : \", prev_r, prev_g, prev_b)\n",
        "\n",
        "    momentum = 0.9 # widely used\n",
        "    learning_rate = 5000 # hyperparameter,\n",
        "    # velocity = 0 # velocity, initialized with 0\n",
        "\n",
        "    iteration_num = 20 # num of iteration, hyperparameter\n",
        "    terminate_constant = 0.01 # termination constant, compare with original class's confidence\n",
        "\n",
        "    start_point = [[0,0,0], [0,0,255], [0,255,0], [255,0,0], [0,255,255], [255,0,255], [255,255,0], [255,255,255]]\n",
        "\n",
        "    sensitive_coordinate = np.array([sensitive_x, sensitive_y])\n",
        "    print(\"Sen : \", sensitive_coordinate)\n",
        "    Xs_List = [] # Note that Xs is 5-tuple of (x,y,r,g,b)\n",
        "\n",
        "    print(\"Startpoint : \", startPoint[0])\n",
        "\n",
        "    # Xs_List will be previous state\n",
        "    for i in range(len(start_point)):\n",
        "        Xs_List.append(np.concatenate((sensitive_coordinate, startPoint[i]), axis = 0))\n",
        "\n",
        "    Xs_List = np.array(Xs_List).reshape((8,5))\n",
        "\n",
        "    image_List = np.empty((0, 32, 32, 3))\n",
        "\n",
        "    # temp = perturb_image(Xs_List[0], img)\n",
        "    # helper.plot_image(temp)\n",
        "    for i in range(len(Xs_List)):\n",
        "        perturbed_image = perturb_image(Xs_List[i], img)\n",
        "        image_List = np.append(image_List, np.array(perturbed_image), axis = 0)\n",
        "\n",
        "    processed = model.color_process(image_List)\n",
        "    Prev_Probs = model._model.predict(processed, batch_size = 8, verbose = 0)\n",
        "    # result is a list of predicted results perturbed with [0, 0, 0], [0, 0, 255], ... , [255, 255, 255]\n",
        "    #print(Prev_Probs[0])\n",
        "\n",
        "    # result[i]기 previous probs 역할, next probs는 init으로 받고..\n",
        "\n",
        "    Next_State_List = np.empty((8,5)) # np.array of [x, y, r, g, b] * 8\n",
        "    Next_Probs = [] # 8 predicted results\n",
        "    velocityList = [] # each state's velocity\n",
        "\n",
        "    for i in range(len(startPoint)):\n",
        "        new_r, new_g, new_b, next_probs, vr, vg, vb = score_init(sensitive_x, sensitive_y, startPoint[i][0], startPoint[i][1], startPoint[i][2], img, model, momentum, learning_rate, target_class)\n",
        "        temp = np.array([new_r, new_g, new_b])\n",
        "\n",
        "        Next_State_List = np.append(Next_State_List, np.concatenate((sensitive_coordinate, temp), axis = 0))\n",
        "        Next_Probs.append(next_probs)\n",
        "        velocityList.append([vr, vg, vb])\n",
        "\n",
        "    #print(Next_Probs[0])\n",
        "    print(Next_State_List[0][0])\n",
        "\n",
        "    for i in range(len(Xs_List)):\n",
        "        continue_flag = True\n",
        "\n",
        "        for t in range(3):\n",
        "            if(Next_State_List[i][t+2] != Xs_List[i][t+2]):\n",
        "                continue_flag = False\n",
        "        if(continue_flag):\n",
        "            continue\n",
        "\n",
        "        for j in range(iteration_num):\n",
        "\n",
        "            r_difference = (Next_State_List[i][2] - Xs_List[i][2]) if (Next_State_List[i][2] - Xs_List[i][2]) != 0 else 1\n",
        "            g_difference = (Next_State_List[i][3] - Xs_List[i][3]) if (Next_State_List[i][3] - Xs_List[i][3]) != 0 else 1\n",
        "            b_difference = (Next_State_List[i][4] - Xs_List[i][4]) if (Next_State_List[i][4] - Xs_List[i][4]) != 0 else 1\n",
        "\n",
        "            r_Slope = (Next_Probs[i][target_class] - Prev_Probs[i][target_class]) / r_difference\n",
        "            g_Slope = (Next_Probs[i][target_class] - Prev_Probs[i][target_class]) / g_difference\n",
        "            b_Slope = (Next_Probs[i][target_class] - Prev_Probs[i][target_class]) / b_difference\n",
        "\n",
        "            velocityList[i][0] = momentum * velocityList[i][0] + learning_rate * r_Slope\n",
        "            velocityList[i][1] = momentum * velocityList[i][1] + learning_rate * g_Slope\n",
        "            velocityList[i][2] = momentum * velocityList[i][2] + learning_rate * b_Slope\n",
        "\n",
        "            New_r = bound(Next_State_List[i][2] + velocityList[i][0])\n",
        "            New_g = bound(Next_State_List[i][3] + velocityList[i][1])\n",
        "            New_b = bound(Next_State_List[i][4] + velocityList[i][2])\n",
        "\n",
        "            xs = np.array([sensitive_x, sensitive_y, New_r, New_g, New_b])\n",
        "\n",
        "            predicted_probs = model.predict_one(perturb_image(xs, img)) # will be deleted during experiment\n",
        "            predicted_class = np.argmax(predicted_probs)\n",
        "            print(str(i) + \"th round's original class's confidence : \", predicted_probs[true_class])\n",
        "            print(str(i) + \"th round's predicted class's confidence : \", predicted_probs[predicted_class])\n",
        "\n",
        "            helper.plot_image(perturb_image(xs, x_test[image_id])[0], true_class, class_names, predicted_class)\n",
        "\n",
        "            if(New_r == Next_State_List[i][2] and New_g == Next_State_List[i][3] and New_b == Next_State_List[i][4]):\n",
        "                print(\"Failure\") # print for test, will be deleted\n",
        "\n",
        "            Prev_Probs[i] = Next_Probs[i]\n",
        "            Next_Probs[i] = predicted_probs\n",
        "\n",
        "            Xs_List[i][2], Xs_List[i][3], Xs_List[i][4] = Next_State_List[i][2], Next_State_List[i][3], Next_State_List[i][4]\n",
        "\n",
        "            Next_State_List[i][2], Next_State_List[i][3], Next_State_List[i][4] = New_r, New_g, New_b"
      ],
      "metadata": {
        "id": "bsa7BVHFRf2L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_id = 384\n",
        "model = resnet\n",
        "sen_list, target_class = sensitive_pixel_sorting_win(image_id, model = resnet)\n",
        "sensitive_ranking = 0\n",
        "x = sen_list[sensitive_ranking][0]\n",
        "y = sen_list[sensitive_ranking][1]\n",
        "Score_based_attack(image_id, model, x, y, target_class)"
      ],
      "metadata": {
        "id": "a_pwxEjrS5zN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}